# TFM_Multiview_3D_Reconstruction

## Table Of Contents

* [Overview](#overview)
* [Structure](#structure)
* [Dataset](#dataset)
* [Requirements](#requirements)
* [Parameters](#parameters)
* [Usage](#usage)
* [Results](#results)
* [Author](#author)
* [Acknowledgements](#acknowledgements)

## üîç Overview

This repository presents the first part of my **Computer Vision Master's thesis project**: a pipeline to annotate the [CMU Panoptic Studio dataset](https://www.cs.cmu.edu/~hanbyulj/panoptic-studio/) with accurate 3D facial reconstructions from multiview images. Using [DAD-3DNet](https://github.com/PinataFarms/DAD-3DHeads) for 3D landmark detection, Bundle Adjustment Structure (BAS) via [CvSBA](https://github.com/willdzeng/cvsba) for 3D refinement and a customed **RANSAC** method for view selection. The approach achieves low reprojection error and generates a refined 3D facial dataset aligned with the original images.

The reconstructions With the execution of this code you will get refined 3D annotations that could be used

For a complete overview of the project, check out the complete report in [TFM_Esther_Vera_Moreno](https://github.com/EstherRobotics/TFM_Multiview_3D_Reconstruction/blob/main/TFM_Esther_Vera_Moreno.pdf). 


 ## üóÇÔ∏è Structure


- **src/**
  - **panoptic_reconstruction/**
    - **config/**
      - `config.yaml`: defines paths, sequences, and global parameters.
      - `manage_paths.py`: class for managing and resolving project paths.
    - **csvsba-1.0.0/**: adapted CvSBA implementation for Bundle Adjustment.
    - **DAD_3DHeads_model/**: code and utilities to extract 3D facial landmarks using DAD-3DNet.
    - **data/**
      - **annotations/**
        - `3D_annotations/`: refined 3D landmark predictions.
        - `nsreprojections/`: 2D landmarks on cropped face images.
        - `reprojections/`: 2D landmarks projected onto full-size images.
      - **cameras_info/**: files used for Bundle Adjustment (`fy.txt`, `mycams.txt`, `mypoints.txt`, `newpoints.txt`).
      - **cropped_imgs_for_evaluation/**: face crops for each sequence (visual check).
      - **files/**
        - `panoptic_ann_train.txt`, `panoptic_ann_valid.txt`, `panoptic_ann_test.txt`: sequence/image lists for batch processing.
    - **face_processor/**
      - `face_cropper.py`, `face_detection.py`, `face_occlusion.py`, `face_pose.py`: modules for detecting, cropping, filtering, and estimating face pose.
    - **panoptic_cameras/**
      - `manage_cameras.py`: loads and handles Panoptic Studio camera parameters.
    - **panoptic_points/**
      - `panoptic_body_points.py`, `panoptic_landmarks.py`: load body/face annotations from Panoptic for evaluation and filtering.
    - **prediction/**
      - `landmarks_selector_3D.py`, `scaled_landmarks_processor.py`: predict, select and scale 3D landmarks.
    - **reconstruction/**
      - `bundle_adjustment.py`: refines 3D points using Bundle Adjustment Structure.
      - `linear_reconstruction.py`: initial 3D triangulation using two views.
      - `projection_utils.py`: projects 3D landmarks onto 2D image planes.
      - `ransac.py`: selects best camera views using a custom RANSAC method.
      - `reconstruction_processor.py`: full pipeline logic for reconstruction and refinement.
    - **utils/**: helper functions for file I/O, data storage, sequence tracking, and image references.
    - `from_txt.py`: batch reconstruction script using lists from `data/files/`.
    - `main.py`: main execution script; runs reconstruction using predefined sequences.

  - **panoptic_reconstruction.egg-info/**: package metadata (autogenerated).
- **pyproject.toml**: project metadata and dependency configuration.
- **requirements.txt**: required Python libraries.
- **README.md**: project overview and usage instructions.
- **TFM_Esther_Vera_Moreno/**: final Master's thesis report.



## üìÑ Dataset 

The dataset used for this code is extracted from [CMU Panoptic Studio](https://www.cs.cmu.edu/~hanbyulj/panoptic-studio/). There were selected a group of sequences that are saved inside [sequence folder](https://github.com/EstherRobotics/TFM_Multiview_3D_Reconstruction/tree/main/src/panoptic_reconstruction/data/sequences) in data. These images were used for the developing and evaluation of the program and can be used to execute the [main](https://github.com/EstherRobotics/TFM_Multiview_3D_Reconstruction/blob/main/src/panoptic_reconstruction/__main__.py) code directly. 

For executing the [from_txt](https://github.com/EstherRobotics/TFM_Multiview_3D_Reconstruction/blob/main/src/panoptic_reconstruction/from_txt.py) code, you should download the sequences corresponding to the paths inside [files](https://github.com/EstherRobotics/TFM_Multiview_3D_Reconstruction/tree/main/src/panoptic_reconstruction/data/files) folder. 


## üíª Requirements

- Create a new python environment
- Install the dependencies contained in [requirements.txt](https://github.com/EstherRobotics/TFM_Multiview_3D_Reconstruction/blob/main/requirements.txt)
- Make sure that your system support C++ compilation for csvba execution. 



## ‚öôÔ∏è Parameters

The management of routes is define inside [config folder](https://github.com/EstherRobotics/TFM_Multiview_3D_Reconstruction/tree/main/src/panoptic_reconstruction/config). Inside confing.ymal is defined: 
- *save_cropped_imgs*: Folder name to save [facial crops](https://github.com/EstherRobotics/TFM_Multiview_3D_Reconstruction/tree/main/src/panoptic_reconstruction/data/cropped_imgs_for_evaluation) used facial landmark detection is performed.
- *annotations*: Folder name to save [annotations](https://github.com/EstherRobotics/TFM_Multiview_3D_Reconstruction/tree/main/src/panoptic_reconstruction/data/annotations) inside data folder.
- *seq_names*: Name of the sequences to process by the main, that are saved in [sequence folder](https://github.com/EstherRobotics/TFM_Multiview_3D_Reconstruction/tree/main/src/panoptic_reconstruction/data/sequences). 

Feel free to adjust this information and manage_paths routes as convenience. 

## üöÄ Usage

After setting up the environment, configure the package with:
```bash
pip install -e .
```
Then navigate to the main project directory and run the main pipeline with:

```bash
python -m panoptic_reconstruction
```

---
The pipeline processes each sequence from the **CMU Panoptic dataset** saved in **sequences**, which is the same frame number captured simultaneously by 31 calibrated cameras. The main steps are:

1. **Multiview Person and Face Detection**  
   For each camera view of a frame, people are detected and facial regions are extracted using the panoptic annotations points. A visibility check is applied to discard occluded faces and cropping is performed based on head orientation (frontal or profile). Each cropped face image and its related coordinates are saved.

2. **3D Landmark Estimation**  
   The cropped facial images are passed through **DAD-3DNet** to estimate 3D facial landmarks.

3. **Camera Selection with RANSAC**  
   A custom **RANSAC** method selects the best subset of camera views for each face based on landmark consistency after linear reconstruction and aplying Bundle Adjustment Structure, evaluating the results against the Panoptic ground-truth annotations.

4. **Final Reconstruction**  
   Only the best-performing camera views obtained by **RANSAC** are combined to produce a final 3D reconstruction, followed by **BAS** refinement.

5. **Output Saving**  
   The final 3D facial reconstruction and its 2D projections on each image are saved before moving to the next sequence.

---


If you want to run the pipeline using predefined path files for a specific subset of sequences, you can use the `from_txt` entry point by typing:

```bash
python -m panoptic_reconstruction.from_txt <method>
```
Here, `method` can be one `train`, `valid` or `test`.
Based on the selected method, the program will automatically use one of the corresponding [files](https://github.com/EstherRobotics/TFM_Multiview_3D_Reconstruction/tree/main/src/panoptic_reconstruction/data/files) containing the path definitions for each sequence.



## üìä Results

As a result, you will obtain three outcomes saved in [annotations](https://github.com/EstherRobotics/TFM_Multiview_3D_Reconstruction/tree/main/src/panoptic_reconstruction/data/annotations): 

- **3D_annotations**: 3D refined reconstruciton annotations.
- **reprojections**: 2D reprojected landmarks from 3D, in coordinates scaled to the facial crops. 
- **nsreprojections**: 2D reprojected landmarks from 3D, with the coordinates following the hdImgs original size from sequences. 

Esentially, both reprojections 2D coordinates are the same but they are saved in different coordinates for covenience. 


This information can be used for reconstruct the 3D mesh of the faces detected (code not included): 







## Authors

* **Esther Vera** -
* [Personal Github](https://github.com/EstherNoumena)
* [ICAERUS Github](https://github.com/ICAERUS-EU/UC1_Crop_Monitoring)
* [LinkedIn](https://www.linkedin.com/in/estherverarobotics/) 

## Acknowledgements
* **Jos√© Miguel Buenaposada** - [Jos√© Miguel B.](https://github.com/jmbuena/) - Master Thesis Tutor
